# Classification
Everything about classification

---------------------------------------------

**Repository summary**

1.  **Intro** ğŸ§³


2.  **Tech Stack** ğŸ¤–


3.  **Features** ğŸ¤³ğŸ½


4.  **Process** ğŸ‘£

5.  **Learning** ğŸ’¡

6.  **Improvement** ğŸ”©

7.  **Running the Project** âš™ï¸

8 .  **More** ğŸ™ŒğŸ½




---------------------------------------------

# :computer: Everything about Classification  :computer:

---------------------------------------------

# 1. Let's talk about Classification.

# I. Introduction: What is Classification?

Tipos de clasificaciÃ³n

# II. Core Components of classication analysis.

# III.  Temas transversales


#

#

#




-------------------------------------------------

2) Temas transversales (previos a los modelos)

PropÃ³sito: antes de estimar modelos, entender aspectos que cambian decisiones y mÃ©tricas.

Desbalanceo de clases

Estrategias: class_weight, re-muestreo (Under/Over), SMOTE/ADASYN, focal loss (para NN/boosting).

CuÃ¡ndo aplicarlas y riesgos (overfitting por oversampling, fuga de informaciÃ³n en CV, etc.).

CalibraciÃ³n de probabilidades

Platt scaling, IsotÃ³nica, temperature scaling (NN). Evaluar con Brier y curvas de confiabilidad.

SelecciÃ³n de umbral

Umbral fijo vs. dependiente de costos / prevalencia. Maximizar F1, J (Youden), utilidad esperada.

MÃ©tricas de evaluaciÃ³n (resumen)

ROCâ€‘AUC vs PRâ€‘AUC (preferir PRâ€‘AUC con clase rara), F1/FÎ², MCC, KS, Logâ€‘loss, Brier.

Curvas ROC/PR y calibraciÃ³n; reporte por clase; matrices de costos cuando aplique.

Estos conceptos aparecerÃ¡n explÃ­citamente en cada tÃ©cnica (secciÃ³n â€œEvaluaciÃ³n adecuadaâ€ y â€œBuenas prÃ¡cticasâ€).

3) TaxonomÃ­a (quÃ© cubriremos)

Lineales probabilÃ­sticos

RegresiÃ³n LogÃ­stica (binaria y multiclase OvR/OvO)

LDA/QDA (AnÃ¡lisis Discriminante Lineal/CuadrÃ¡tico)

Naive Bayes (Gaussiano/Multinomial/Bernoulli)

MÃ¡rgenes y planos

PerceptrÃ³n

SVM (lineal y kernel: RBF, polinomial)

Basados en instancias

kâ€‘NN

Ãrboles

Decision Trees (CART, Gini/EntropÃ­a)

Ensamblajes

Bagging, Random Forest

AdaBoost, Gradient Boosting

XGBoost, LightGBM, CatBoost

Redes Neuronales (â‰¥ 3 tÃ©cnicas de clasificaciÃ³n)

MLP (feedâ€‘forward) para tabular/texto vectorizado

CNN simple para imÃ¡genes (clasificaciÃ³n bÃ¡sica)

RNN/LSTM/GRU para secuencias (p.ej., texto/tiempo) con salida de clase

4) Plantilla comÃºn por tÃ©cnica (doc)

Cada archivo en docs/ seguirÃ¡ esta estructura uniforme:

Â¿QuÃ© es? (definiciÃ³n en 3â€“5 lÃ­neas)

Â¿Para quÃ© sirve? (casos de uso tÃ­picos)

IntuiciÃ³n (figura/visiÃ³n geomÃ©trica o probabilÃ­stica)

Fundamento matemÃ¡tico (expresiÃ³n/funciÃ³n de pÃ©rdida & decisiÃ³n)

Algoritmo de entrenamiento (pasos o pseudoâ€‘cÃ³digo)

Supuestos & condiciones (cuando el modelo se comporta mejor)

HiperparÃ¡metros clave (tabla con significado e impacto)

Complejidad (tiempo/espacio, n vs d)

Buenas prÃ¡cticas (escalado, regularizaciÃ³n, validaciÃ³n)

Pitfalls comunes (leakage, overfitting, multicolinealidad, etc.)

ImplementaciÃ³n en librerÃ­as

Python: librerÃ­a y clase/funciÃ³n (sklearn.linear_model.LogisticRegression, xgboost.XGBClassifier, lightgbm.LGBMClassifier, catboost.CatBoostClassifier, torch.nn.Module/keras.Model, etc.) + parÃ¡metros relevantes y su efecto.

R (opcional): glm, MASS::lda/qda, e1071::svm, randomForest, xgboost, lightgbm, catboost, keras.

CÃ³digo mÃ­nimo (Python y/o R, dataset sintÃ©tico + mÃ©trica principal)

CuÃ¡ndo SÃ usarla (idÃ³nea) y cuÃ¡ndo NO usarla (antiâ€‘patrones)

Referencias

Papers (3): trabajos canÃ³nicos/seminales.

Web (2): documentaciÃ³n oficial o tutoriales reputados.

CASO DE LA REGRESIÃ“N LOGISTICA


6) MÃ©tricas (resumen de docs/99-evaluation-metrics.md)

ROCâ€‘AUC vs PRâ€‘AUC (preferir PRâ€‘AUC con clase positiva rara)

F1 / FÎ²; MCC; Brier; KS; Logâ€‘loss

Curvas: ROC, PR, calibraciÃ³n; umbral Ã³ptimo por mÃ©trica/escenario de costos


